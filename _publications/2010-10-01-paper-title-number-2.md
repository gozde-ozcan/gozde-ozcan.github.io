---
title: "Stochastic Submodular Maximization via Polynomial Estimators"
collection: publications
permalink: /publication/stoch-sub-max
excerpt: 'In this paper, we study stochastic submodular maximization problems with gen- eral matroid constraints, which naturally arise in online learning, team formation, facility location, influence maximization, active learning and sensing objective functions. In other words, we focus on maximizing submodular functions that are defined as expectations over a class of submodular functions with an unknown distribution. We show that for monotone functions of this form, the stochastic continuous greedy algorithm attains an approxima- tion ratio (in expectation) arbitrarily close to (1 − 1/e) ≈ 63% using a polynomial estimation of the gradient. We argue that using this polynomial estimator instead of the prior art that uses sampling eliminates a source of randomness and experimentally reduces execution time.'
date: 2023-05-28
venue: 'PAKDD 2023'
venueurl: 'https://pakdd2023.org'
codeurl: 'https://github.com/neu-spiral/StochSubMax'
slidesurl: 'http://gozde-ozcan.github.io/files/PAKDD23Presentation.pdf'
paperurl: 'http://gozde-ozcan.github.io/files/StochasticSubmodularMaximizationViaPolynomialEstimators.pdf'
authors: '<b>Gözde Özcan</b>, and Stratis Ioannidis'
citation: 'Özcan, Gözde, and Stratis Ioannidis. (2023). &quot;Stochastic Submodular Maximization via Polynomial Estimators.&quot; <i>Pacific-Asia Conference on Knowledge Discovery and Data Mining</i>.'
---

In this paper, we study stochastic submodular maximization problems with gen- eral matroid constraints, which naturally arise in online learning, team formation, facility location, influence maximization, active learning and sensing objective functions. In other words, we focus on maximizing submodular functions that are defined as expectations over a class of submodular functions with an unknown distribution. We show that for monotone functions of this form, the stochastic continuous greedy algorithm attains an approxima- tion ratio (in expectation) arbitrarily close to (1 − 1/e) ≈ 63% using a polynomial estimation of the gradient. We argue that using this polynomial estimator instead of the prior art that uses sampling eliminates a source of randomness and experimentally reduces execution time.
